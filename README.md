# ğŸ¤– Deepfake Detection System

<div align="center">

![Status](https://img.shields.io/badge/Status-Experimental-orange?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![CUDA](https://img.shields.io/badge/CUDA-12.4-76B900?style=for-the-badge&logo=nvidia&logoColor=white)

**Deep learning system for detecting manipulated facial video content**

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Results](#-current-results) â€¢ [Limitations](#-known-limitations) â€¢ [Future Work](#-future-improvements)

</div>

---

## ğŸ“Œ Overview

An experimental deepfake detection system built with PyTorch and EfficientNet-B1, trained on multiple academic datasets (FaceForensics++, Celeb-DF). This project demonstrates deep learning techniques for video manipulation detection with GPU acceleration.

**Current Status:** ğŸŸ¡ **Experimental** - Works well on training datasets, needs improvement for real-world generalization.

---

## âœ¨ Features

âœ… **Multi-Dataset Training** - Trained on 25,000+ videos from FaceForensics++ and Celeb-DF  
âœ… **GPU Accelerated** - CUDA-optimized inference with mixed precision training  
âœ… **Smart Class Balancing** - 70/30 sampling ratio to prevent prediction bias  
âœ… **Video-Level Splits** - Prevents data leakage during training  
âœ… **Grad-CAM Visualization** - Shows which facial regions the model focuses on  
âœ… **Frame-by-Frame Analysis** - Detailed confidence scores per frame  
âœ… **Temporal Consistency Check** - Analyzes prediction stability across video  

---

## ğŸ“Š Current Results

### Training Performance

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   TRAINING RESULTS (Jan 2026)          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Test Accuracy:    83.73%               â•‘
â•‘ Precision:        91.24%               â•‘
â•‘ Recall:           84.91%               â•‘
â•‘ F1-Score:         87.96%               â•‘
â•‘                                        â•‘
â•‘ Confusion Matrix:                      â•‘
â•‘   True Negatives:  2,755               â•‘
â•‘   False Positives: 647                 â•‘
â•‘   False Negatives: 1,198               â•‘
â•‘   True Positives:  6,740               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Trained On:**
- FaceForensics++ (original, deepfakes, face2face, faceswap, neuraltextures, DeepFakeDetection)
- Celeb-DF (Celeb-real, YouTube-real, Celeb-synthesis)
- Total: 12,593 videos, 150,288 frames

**Performance Metrics:**
- Inference Speed: ~230ms per frame (RTX 4060 Laptop GPU)
- Memory Usage: ~2-3GB VRAM
- Batch Size: 24 frames
- Model Size: 7.17M parameters

---

## âš ï¸ Known Limitations

**Current Issues:**

ğŸ”´ **Overfitting to Training Data**
- Model performs well (83%+) on FaceForensics++/Celeb-DF test sets
- **Poor generalization to real-world videos** - tends to classify authentic videos as fake
- Likely memorized dataset-specific artifacts rather than learning general deepfake features

ğŸŸ¡ **Dataset Bias**
- Training data heavily skewed toward specific deepfake generation methods
- May not detect newer deepfake techniques (Stable Diffusion, advanced GANs)
- Limited diversity in facial features and lighting conditions

ğŸŸ¡ **Other Limitations**
- Requires clear, frontal face visibility
- Lower accuracy on compressed/low-quality videos
- No multi-face support (single face per frame)
- Sensitive to video quality and compression

**Why This Happens:**
- Academic datasets (FaceForensics++, Celeb-DF) have specific visual signatures
- Model learned these signatures instead of general manipulation features
- Need more diverse, realistic training data for real-world deployment

---

## ğŸ› ï¸ Tech Stack

| Component | Version | Purpose |
|-----------|---------|---------|
| Python | 3.10+ | Programming language |
| PyTorch | 2.0+ | Deep learning framework |
| CUDA | 12.4 | GPU acceleration |
| EfficientNet-B1 | Pretrained | CNN backbone |
| OpenCV | 4.5+ | Video processing |
| NumPy | 1.20+ | Numerical computing |
| Matplotlib/Seaborn | 3.x/0.13 | Visualization |
| scikit-learn | 1.7+ | Metrics & evaluation |

---

## ğŸš€ Installation

### Prerequisites
- NVIDIA GPU with CUDA support (recommended)
- Python 3.10 or higher
- Git

### Step 1: Clone Repository

```bash
git clone https://github.com/YashovardhanB28/deepfake-detector-production.git
cd deepfake-detector-production
```

### Step 2: Create Virtual Environment

```bash
# Windows
python -m venv venv_gpu
venv_gpu\Scripts\activate

# macOS/Linux
python3 -m venv venv_gpu
source venv_gpu/bin/activate
```

### Step 3: Install Dependencies

```bash
# Upgrade pip
python -m pip install --upgrade pip

# Install PyTorch with CUDA (for GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Install other requirements
pip install opencv-python pillow numpy matplotlib seaborn scikit-learn tqdm
```

### Step 4: Verify Installation

```bash
python src/setup_checker.py
```

Should show âœ… for Python, packages, GPU, and disk space.

---

## ğŸ“– Usage

### Quick Start

```bash
# Test a video
python src/3_test_video.py
```

When prompted, enter your video path:
```
ğŸ“¹ Enter video path: C:\path\to\your\video.mp4
```

### Training From Scratch

**1. Extract Frames**

```bash
python src/1_extract_frames.py
```

This processes videos from:
- `data/faceforensics/archive/FaceForensics++_C23/`
- `data/archive (1)/` (Celeb-DF)

**2. Train Model**

```bash
python src/2_train_model.py
```

Training configuration:
- 10 epochs
- Batch size: 24
- Learning rate: 1e-4
- Smart sampling (70/30 fake/real ratio)
- Weighted loss function
- Mixed precision training

**3. Test Model**

```bash
python src/3_test_video.py
```

### Output Explanation

```
ğŸ“Š FRAME-BY-FRAME ANALYSIS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Frame 1 @ 0.00s:
   ğŸ”´ Prediction: FAKE
   Confidence: 89.45%
   Probabilities: Real=10.6%, Fake=89.4%
   â€¢ ğŸ”´ VERY HIGH confidence - clear fake characteristics
   â€¢ âœ… Highly consistent across frames (85.2%)

ğŸ¯ TEMPORAL CONSISTENCY ANALYSIS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Fake detections: 9 (90.0%)
   Real detections: 1 (10.0%)
   Prediction consistency: 90.0%

âš–ï¸ FINAL VERDICT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ğŸ”´ DEEPFAKE DETECTED
   Confidence: 87.34%
```

**Visualizations saved to:** `analysis_results/<video_name>/`
- `frame_analysis.png` - Grad-CAM heatmaps showing attention regions
- `confidence_timeline.png` - Confidence scores over time
- `statistics.png` - Overall statistics

---

## ğŸ—ï¸ Architecture

### Model Pipeline

```
Input Video (MP4/AVI)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frame Extraction            â”‚
â”‚ - Extract 10 evenly-spaced  â”‚
â”‚ - Resize to 224x224         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing               â”‚
â”‚ - Normalize to ImageNet     â”‚
â”‚ - Data augmentation (train) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EfficientNet-B1 Backbone    â”‚
â”‚ - Pretrained on ImageNet    â”‚
â”‚ - Feature extraction        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification Head         â”‚
â”‚ - FC: 1280 â†’ 512 (ReLU)     â”‚
â”‚ - Dropout: 0.3              â”‚
â”‚ - FC: 512 â†’ 2 (Softmax)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Temporal Aggregation        â”‚
â”‚ - Multi-frame voting        â”‚
â”‚ - Confidence averaging      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final Verdict: REAL / FAKE
```

### Key Techniques

**Smart Class Balancing**
- Original: 85% fake / 15% real (severe imbalance)
- Applied: 70% fake / 30% real (balanced sampling)
- Weighted loss to handle remaining imbalance

**In-Place Operation Fix**
- Disabled `inplace=True` in all ReLU/SiLU activations
- Prevents gradient computation errors with mixed precision training

**Grad-CAM Visualization**
- Highlights which facial regions influenced the decision
- Helps understand what the model "sees"

---

## ğŸ“ Project Structure

```
deepfake-detector-production/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ 1_extract_frames.py      # Frame extraction from datasets
â”‚   â”œâ”€â”€ 2_train_model.py         # Training script
â”‚   â”œâ”€â”€ 3_test_video.py          # Interactive testing
â”‚   â””â”€â”€ setup_checker.py         # Environment verification
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ faceforensics/           # FaceForensics++ dataset
â”‚   â”œâ”€â”€ archive (1)/             # Celeb-DF dataset
â”‚   â””â”€â”€ all_datasets_frames/     # Extracted frames
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pth           # Trained weights (83.73% acc)
â”œâ”€â”€ analysis_results/            # Test outputs with visualizations
â”œâ”€â”€ documentation/               # Guides and documentation
â”œâ”€â”€ old_versions/                # Previous experimental scripts
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```

---

## ğŸ”¬ Training Details

### Dataset Information

**FaceForensics++ (C23 compression)**
- Original: 2,000 videos (real)
- Deepfakes: 2,000 videos
- Face2Face: 2,000 videos
- FaceSwap: 2,000 videos
- NeuralTextures: 2,000 videos
- DeepFakeDetection: 2,000 videos

**Celeb-DF**
- Celeb-real: 1,180 videos
- YouTube-real: 600 videos
- Celeb-synthesis: 11,278 videos (fake)

**After Smart Sampling:**
- Real videos: 3,778 (100% kept)
- Fake videos: 8,815 (sampled from 21,270)
- Total: 12,593 videos
- Frame count: 75,558 frames (6 per video)

### Training Hyperparameters

```python
BATCH_SIZE = 24
NUM_EPOCHS = 10
LEARNING_RATE = 1e-4
WEIGHT_DECAY = 1e-5
IMG_SIZE = 224
DROPOUT = 0.3
OPTIMIZER = AdamW
SCHEDULER = ReduceLROnPlateau
MIXED_PRECISION = True
```

### Data Augmentation (Training Only)

- Random horizontal flip (50%)
- Random rotation (Â±10Â°)
- Color jitter (brightness, contrast, saturation: Â±20%)

---

## ğŸ”® Future Improvements

### Planned Enhancements

**High Priority:**
- [ ] **Improve Real-World Generalization**
  - Add diverse real-world videos to training
  - Implement domain adaptation techniques
  - Use data augmentation that simulates real-world conditions
  
- [ ] **Add More Datasets**
  - DFDC (Facebook Deepfake Detection Challenge)
  - WildDeepfake
  - Custom collected real-world videos
  
- [ ] **Model Architecture Improvements**
  - Try Vision Transformers (ViT)
  - Ensemble multiple models
  - Add temporal modeling (LSTM/GRU)

**Medium Priority:**
- [ ] Multi-face detection support
- [ ] Audio-visual analysis (detect audio deepfakes)
- [ ] Real-time video stream processing
- [ ] Web UI for easy testing
- [ ] REST API for integration

**Low Priority:**
- [ ] Mobile deployment (ONNX/TFLite)
- [ ] Explainable AI features
- [ ] Adversarial robustness testing
- [ ] Model compression/quantization

### Known Issues to Fix

1. **Overfitting** - Model needs diverse training data
2. **Compression sensitivity** - Improve robustness to video compression
3. **Lighting sensitivity** - Handle varied lighting conditions better
4. **Partial face handling** - Detect when face is partially visible

---

## ğŸ¤ Contributing

Contributions welcome! This is an experimental project with room for improvement.

**Ways to help:**
- Test on your own videos and report results
- Suggest dataset additions
- Propose architecture improvements
- Fix bugs or improve code quality
- Improve documentation

**To contribute:**
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Make your changes
4. Test thoroughly
5. Submit a pull request

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file

---

## ğŸ‘¤ Author

**Yashovardhan Bangur**

ğŸ® XR/Unreal Engine Developer  
ğŸ¤– Applied AI Researcher (ML & NLP)  
ğŸ“ Based in Ahmedabad, Gujarat ğŸ‡®ğŸ‡³  
ğŸŒ Currently in New Jersey, USA

### Connect

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/yashovardhan-bangur-83677a31a)
[![Portfolio](https://img.shields.io/badge/Portfolio-FF6B6B?style=for-the-badge&logo=firefoxbrowser&logoColor=white)](https://yashovardhanbangurportfolio.netlify.app/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/YashovardhanB28)

---

## ğŸ™ Acknowledgments

- **PyTorch Team** - Deep learning framework
- **NVIDIA** - CUDA GPU acceleration
- **FaceForensics++ Team** - Dataset and research
- **Celeb-DF Team** - Dataset contribution
- **Research Community** - Ongoing deepfake research

---

## ğŸ“ Contact

ğŸ“§ Email: yashovardhanbangur2801@gmail.com  
ğŸ› Issues: [GitHub Issues](https://github.com/YashovardhanB28/deepfake-detector-production/issues)

---

<div align="center">

â­ **If this project helped you, please star it!**

**Last Updated:** January 2026

*"Detecting deception through deep learning - an experimental journey."*

</div>
